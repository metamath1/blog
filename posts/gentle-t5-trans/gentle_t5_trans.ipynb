{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b481ef-b6ef-4dcb-a7f2-53ad355b7c7a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"A Gentle Introduction to Creating an English-to-Korean translator with Transformers\"\n",
    "author: \"Jo, Joonu\"\n",
    "date: \"2023-02-27\"\n",
    "image: translate.png\n",
    "categories: [ai, code, transformers]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b9fe1-fa93-4af7-9ccd-f872322c759e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 친절한 영어-한국어 번역기 만들기 A Gentle Introduction to Creating an English-to-Korean translator with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee13d5f-3387-4583-9ccc-c0640ed8d1ac",
   "metadata": {},
   "source": [
    "트랜스포머가 딥러닝 세상을 지배한 지금 과거 CNN, RNN을 모르고 딥러닝을 안다고 할 수 없듯이 이제는 트랜스포머를 이해하지 못하고 딥러닝을 공부한다고 말할 수 없는 시대가 되었다.\n",
    "\n",
    "트랜스포머가 초기 타겟한 작업이 번역이기 때문에 트랜스포머를 설명하는 글에서 단골로 등장하는 예제가 번역기 예제다. 주로 영어-독일어, 영어-스페인어 예제가 많다. 하지만 쉽게 접할 수 있는 알파벳권 언어 사이의 번역기 예제에 비해 영어-한국어 데이터를 사용해서 번역기를 학습시키는 예제는 이상하리만큼 찾아보기 힘들었다. 왜 그런지 이유는 잘 모르겠지만 어쨌든 거의 없다. 그래서 영어-한국어 문장쌍이 들어있는 원시데이터를 사용해 T5 모델로 영어-한국어 번역기를 데모 수준 정도로 학습하는 예제를 만들어 블로그에 포스팅하면 많은 사람들에게 도움이 되지 않을까 해서 이 글을 적게 되었다.\n",
    "\n",
    "이 글에서는 트랜스포머에 대한 기초적인 내용은 다루지 않고 오직 데이터를 어떻게 준비하고, 어떻게 데이터를 모델에 입력하여 학습을 시키고, 마지막으로 어떻게 영어로 부터 한국어 번역 문장을 출력시키는가 하는 것에만 초점을 맞추었다. 그리고 **코드를 복잡하게 만드는 그 어떤 테크닉도 사용하지 않는다.** 오로지 가장 간단하게 한국어 번역기를 구축하는데만 집중할 것이다. 사실 이 글의 대부분 내용은 허깅페이스 [도움말](https://huggingface.co/course/chapter7/4?fw=pt)에 있는 것을 정리한것에 지나지 않는다. 하지만 입문자나 이제 막 트랜스포머를 이용해서 한국어 번역기를 만들고자 하는 사람들은 허깅페이스 도움말을 보고 이 내용을 모두 정리하기 쉽지 않은 것이 사실이어서 이글이 꽤 도움이 되리라 생각한다.\n",
    "\n",
    "<a href=\"\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be8e63-80b5-45f9-9f63-0a481777d09c",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22528325-7cb0-40b2-9361-99c5012b827e",
   "metadata": {},
   "source": [
    "먼저 허깅페이스의 트랜스포머스 라이브러리를 임포트 한다. 본인 컴퓨터에 허깅페이스 트랜스포머스 라이브러리가 설치되어 있지 않다면 다음 명령어로 설치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d2579-3dae-408c-ae0e-091a2a84936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0432ced-9cb3-4988-b039-40857a8ba476",
   "metadata": {},
   "source": [
    "그 다음 해야할 일은 데이터 셋을 다운받는 것이다. 다음 명령을 실행해서 허깅페이스 `Datasets` 라이브러리를 설치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90ff00-2d99-48c6-b52d-8ddc8c781131",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2540e8-3fdb-4ca5-87f5-ea8963f9ffd8",
   "metadata": {},
   "source": [
    "모두 설치가 완료되었다면 데이터 셋을 다운받아야 한다. 먼저 허깅페이스 사이트에 접속해서 상단 메뉴에 Datasets를 클릭하고 아래 그림처럼 검색 조건을 다음처럼 맞추면\n",
    "\n",
    "- 좌측 작은 메뉴에서 Languages를 선택한다.\n",
    "- Languages 하단에 보이는 여러 언어중에 Korean을 선택한다.\n",
    "- 다시 우측 검색 필터 창에 en을 적는다.\n",
    "\n",
    "데이터 셋 네 개가 보이는데 `bongsoo/news_talk_en_ko`를 사용하도록 하겠다.\n",
    "\n",
    "\n",
    "<img src=\"dataset.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f256e4cd-8025-4600-a749-31ef2b32720a",
   "metadata": {},
   "source": [
    "`bongsoo/news_talk_en_ko`를 클릭해서 나오는 화면에서 `Files and Versions`를 클릭하면 tsv 파일이 보이는데 이 파일에는 영어 문장과 한국어 문장이 한줄에 탭 문자로 구분되어 적혀있다. 로컬 디스크이 이 파일을 다운받고 파일을 읽어보면 다음처럼 확인된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf899d4-94e2-44da-be99-dd3bd175785c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skinner's reward is mostly eye-watering.\t스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.\n",
      "Even some problems can be predicted.\t심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.\n",
      "Only God will exactly know why.\t오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.\n",
      "Businesses should not overlook China's dispute.\t중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.\n",
      "Slow-beating songs often float over time.\t박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.\n"
     ]
    }
   ],
   "source": [
    "!head -5 news_talk_en_ko_train_130000.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df87bf1-49d0-4f34-828e-ffadcd58ca06",
   "metadata": {},
   "source": [
    "데이터 파일은 아주 단순한 형태인 것을 알 수 있다. 직접 tsv파일을 다운받아서 사용해도 되나 허깅페이스 허브로 부터 바로 다운받아 사용하는 편이 더 편하다. 다음 명령으로 다운받을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93bf4a49-43d5-4bd2-8369-8a0b395a2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋을 다운받을 함수를 임포트 한다.\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5956b760-f263-4569-b4e6-5f88ec235cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration bongsoo--news_talk_en_ko-e7f00bc8f76f18d5\n",
      "Found cached dataset csv (/home/metamath/.cache/huggingface/datasets/bongsoo___csv/bongsoo--news_talk_en_ko-e7f00bc8f76f18d5/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df63352363494b1b94a1134732d5659a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 좀 전에 알아본 체크포인트를 사용해서 데이터를 받아온다.\n",
    "en_ko = load_dataset(\"bongsoo/news_talk_en_ko\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00671055-4398-4306-9475-f49f773d8425",
   "metadata": {},
   "source": [
    "이제 데이터 객체를 확인해보면 `DatasetDict`라는 것을 알 수 있고 안에 `train` 키만 있는 것이 확인된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69638a74-2941-4a05-aa41-37ccaf8166e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: [\"Skinner's reward is mostly eye-watering.\", '스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.'],\n",
       "        num_rows: 1299999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943f0d6-7eba-4d3f-9ef1-bccb85c2830c",
   "metadata": {},
   "source": [
    "`train`키에 `Dataset` 객체가 하나 있는데 `features`가 첫번째 데이터로 되어있고 행수는 1299999개인 것을 보아 데이터 파일에 컬럼명이 적혀있는 헤더라인이 없어서 첫줄을 헤더로 읽은것 같다. 첫줄을 데이터로 다시 집어 넣고 컬럼명은 `en`, `ko`로 설정하기 위해 데이터 셋을 `pandas`로 읽어드린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd46899-4aea-435d-b480-8dea8adc2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1cd4b2-40de-40e5-82ae-85b5af5fe19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 허깅페이스 데이터셋을 판다스 포맷으로 세팅\n",
    "en_ko.set_format(type=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34946bd2-2ce7-4773-94de-656a405fc122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skinner's reward is mostly eye-watering.</th>\n",
       "      <th>스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Even some problems can be predicted.</td>\n",
       "      <td>심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only God will exactly know why.</td>\n",
       "      <td>오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Businesses should not overlook China's dispute.</td>\n",
       "      <td>중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slow-beating songs often float over time.</td>\n",
       "      <td>박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't even consider uninsured treatments.</td>\n",
       "      <td>보험 처리가 안 되는 비급여 시술은 엄두도 못 낸다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Skinner's reward is mostly eye-watering.  \\\n",
       "0             Even some problems can be predicted.   \n",
       "1                  Only God will exactly know why.   \n",
       "2  Businesses should not overlook China's dispute.   \n",
       "3        Slow-beating songs often float over time.   \n",
       "4      I can't even consider uninsured treatments.   \n",
       "\n",
       "     스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.  \n",
       "0  심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.  \n",
       "1      오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.  \n",
       "2    중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.  \n",
       "3     박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.  \n",
       "4       보험 처리가 안 되는 비급여 시술은 엄두도 못 낸다.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'train'키의 모든 행을 DataFrame df에 할당\n",
    "df = en_ko[\"train\"][:]\n",
    "\n",
    "# 잘 담겼는지 확인한다.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a0992-16a4-4bc3-8c9d-001359559bbd",
   "metadata": {},
   "source": [
    "예상처럼 첫 줄이 헤더가 되었으니 이를 수정한 `DataFrame`을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e15b742-e808-4b15-99a0-28b4bb5d09dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Skinner's reward is mostly eye-watering.\",\n",
       " '스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_0 = list(df.columns)\n",
    "example_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfe588c-5cbf-4b33-8c0e-14a72277b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_0_df = pd.DataFrame({col: [value] for col, value in zip(('en', 'ko'), example_0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b61a1c-b538-4051-a5d5-757ea1cce1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ('en', 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d16fbbc-1baf-47a1-b15b-abddf9b372e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ko</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skinner's reward is mostly eye-watering.</td>\n",
       "      <td>스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Even some problems can be predicted.</td>\n",
       "      <td>심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only God will exactly know why.</td>\n",
       "      <td>오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Businesses should not overlook China's dispute.</td>\n",
       "      <td>중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Slow-beating songs often float over time.</td>\n",
       "      <td>박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                en  \\\n",
       "0         Skinner's reward is mostly eye-watering.   \n",
       "1             Even some problems can be predicted.   \n",
       "2                  Only God will exactly know why.   \n",
       "3  Businesses should not overlook China's dispute.   \n",
       "4        Slow-beating songs often float over time.   \n",
       "\n",
       "                                   ko  \n",
       "0    스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.  \n",
       "1  심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.  \n",
       "2      오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.  \n",
       "3    중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.  \n",
       "4     박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ko_df = pd.concat([example_0_df, df],).reset_index(drop=True)\n",
    "en_ko_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc5662-faf2-426a-aa6a-afe80d7b19a6",
   "metadata": {},
   "source": [
    "이렇게 데이터 셋을 `DataFrame`으로 만들었다. 이제 이 `en_ko_df`로 부터 다시 허깅페이스 데이터 셋을 생성하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "681f6ed9-d488-47cb-a24a-23626146a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0631eb3d-ee3d-4264-89dd-2395a1bee4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(en_ko_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb85dddc-0e58-4418-8181-83daba3c6049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['en', 'ko'],\n",
       "    num_rows: 1300000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab6f02a-8537-4d36-b65e-0d396cf151a9",
   "metadata": {},
   "source": [
    "다시 데이터 셋을 확인해보면 `features`가 제대로 표시되고 샘플 수도 1300000개 인것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05c2bb-f303-46d3-8302-89f37549f441",
   "metadata": {},
   "source": [
    "이렇게 만들어진 `DataFrame`으로 부터 데이터 셋이 잘 초기화되는 것을 확인했으니 `en_ko_df`를 세조각으로 쪼개서 tsv파일로 저장하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604f23cd-d95c-4337-be34-3a09635e61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 데이터 셋의 샘플수를 정한다.\n",
    "num_train = 1200000\n",
    "num_valid = 90000\n",
    "num_test = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4112c-c615-4f51-9297-0f73c4ae6290",
   "metadata": {},
   "source": [
    "설정된 크기만큼 `DataFrame`을 자른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27a055e4-0df6-449f-899d-6146cf2abe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ko_df_train = en_ko_df.iloc[:num_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0651dd95-6095-413a-b19b-a839c3b59a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ko_df_valid = en_ko_df.iloc[num_train:num_train+num_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9e662e9-9d1e-4103-8780-fc6dac2bd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ko_df_test = en_ko_df.iloc[-num_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011f014-cac7-47d5-873e-70ab59a39e04",
   "metadata": {},
   "source": [
    "다시 `tsv`파일로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cb755cb-d83e-4c2a-a92b-54d0cf58fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ko_df_train.to_csv(\"train.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc2a51b7-f69b-4b80-8e1d-d3d9f60c227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ko_df_valid.to_csv(\"valid.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f0108ff-5aa4-4325-8b66-6a07804bd188",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ko_df_test.to_csv(\"test.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6f650-7084-49c0-a6a3-3d32ef14f46a",
   "metadata": {},
   "source": [
    "이렇게 `tsv`파일 세개로 데이터를 정리했다. 이제 필요할때 이 파일을 읽어 허깅페이스 데이터셋을 만들 수 있다.\n",
    "\n",
    "아래처럼 스플릿을 정의한 사전을 `load_dataset`에 넘기면 된다. 이때 `delimiter`를 탭 문자로 지정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d99b4a2-78d6-4984-8207-b87ab4c512be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\"train\": \"train.tsv\", \"valid\": \"valid.tsv\", \"test\": \"test.tsv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6b8272a-0351-4305-b18a-4529ec2f9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d166a7cf4252597d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/metamath/.cache/huggingface/datasets/csv/default-d166a7cf4252597d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7244b69bdd884b4299718f17d95ae43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a0ee2ba9bb4853bfdd8b87ff33c79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/metamath/.cache/huggingface/datasets/csv/default-d166a7cf4252597d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae68b12959f4bbc82c2385c018744a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset =  load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0922f1-ea9d-404c-95b0-c72edebc0adb",
   "metadata": {},
   "source": [
    "제대로 로딩되었는지 `dataset`을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7e84925-56f0-4374-a756-f35a5057bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'ko'],\n",
       "        num_rows: 1200000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['en', 'ko'],\n",
       "        num_rows: 90000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'ko'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a46daa-863e-4438-a848-742ee3638ed7",
   "metadata": {},
   "source": [
    "`DatasetDict`에 `train`, `valid`, `test` 키로 120만 문장, 9만 문장, 1만 문장이 저장된 것을 확인할 수 있다.\n",
    "\n",
    "이 데이터 셋에서 개별 샘플에 대한 접근은 `[split][feature][row num]` 형태로 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cf854ed-5b0d-444b-b35e-d1f1e5b58e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Skinner's reward is mostly eye-watering.\", 'Even some problems can be predicted.', 'Only God will exactly know why.'] ['스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.', '심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.', '오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.']\n"
     ]
    }
   ],
   "source": [
    "# train 스플릿에서 영어 3개와 한국어 3개 샘플을 가져온다.\n",
    "print(dataset['train']['en'][:3], dataset['train']['ko'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fd4cf6-fe95-4ab5-ac6e-7539cc1fe594",
   "metadata": {},
   "source": [
    "그런데 `feature`와 `row num`은 순서를 바꿔서 사용할 수 도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70014441-e8a8-496c-bf3f-a40b7c91a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Skinner's reward is mostly eye-watering.\", 'Even some problems can be predicted.', 'Only God will exactly know why.'] ['스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.', '심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.', '오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][:3]['en'], dataset['train'][:3]['ko'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89453b75-80b2-40f2-a0ba-ca3977138449",
   "metadata": {},
   "source": [
    "데이터를 어떻게 조회하는지는 데이터 구성 방식에 따라 조금씩 다르므로 데이터 셋을 보고 몇번 해보면 금방 접근법을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d3379-b806-4e46-90c3-fcc3691c03ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hugging face\n",
    "\n",
    "데이터 셋 준비를 마쳤으니 학습할 차례이다. 허깅페이스에서 제공하는 필요 클래스를 임포트 한다.\n",
    "\n",
    "먼저 선학습 모델을 사용하기 위한 클래스를 임포트 한다. `AutoTokenizer`는 선학습된 모델이 사용한 토크나이저를 읽기 위해 필요하며 `AutoModelForSeq2SeqLM`은 시퀀스 투 스퀀스 방식으로 작동하는 선학습된 모델을 불러 올 때 마지막에 분류기 헤드를 붙여서 모델을 로딩하기 위해 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91addd01-dae9-4367-a6ea-560d7c6761b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 20:50:48.785319: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 20:50:48.886805: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-28 20:50:48.903288: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-28 20:50:49.229160: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:\n",
      "2023-02-28 20:50:49.229214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:\n",
      "2023-02-28 20:50:49.229217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4b0ba-f3a8-4f09-9131-007ab06cc855",
   "metadata": {},
   "source": [
    "다음은 데이터 콜레이터를 임포트한다. 시쿼스 투 시퀀스 학습 과정은 인코더 입력 시퀀스, 디코더 입력 시퀀스, 디코더 출력 시퀀스를 필요로 하는데 미니배치로 부터 이를 적절히 정리해서 모델에 입력하는 작업이 필요하다. 예를 들면 미니 배치 내에 있는 인코더 입력 시퀀스의 길이를 맞춘다든지 디코더 입력시퀀스를 오른쪽으로 한칸 쉬프트시켜 디코더 출력 시퀀스를 만드는 작업등이 콜레이터에서 일어나는 작업인데 이런 작업을 `DataCollatorForSeq2Seq`가 자동으로 처리하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "330f2560-3457-4c64-907f-63dc78246208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661209be-091b-410d-9e13-4ebfff38e633",
   "metadata": {},
   "source": [
    "그리고 학습에 필요한 클래스를 임포트 한다. 학습에 필요한 설정을 `Seq2SeqTrainingArguments`에 정의하고 실제 학습은 `Seq2SeqTrainer`로 하게 된다.\n",
    "`Seq2SeqTrainer`는 `generate()`함수를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "301e0129-a447-4949-b572-5fe605702707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11029e-0c2a-4437-99d2-41aa1c6acce3",
   "metadata": {},
   "source": [
    "허깅페이스 라이브러리로는 마지막으로 데이터 셋을 로딩하는 함수와 번역 결과를 측정할 함수를 로딩한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9741b79e-1bc9-4f3b-8163-820f237fdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ef6f3-a0ea-4d8e-bcc7-aaf4f89d8de8",
   "metadata": {},
   "source": [
    "그외 필요한 각종 라이브러리를 임포트 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1354b5d1-17f3-4b2a-a62b-8098855b712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704916ef-74a8-4329-a4a2-4559f5c781a6",
   "metadata": {},
   "source": [
    "허깅페이스에서 파이토치 기반 구현을 사용하므로 gpu가 있다면 `device`를 세팅한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac2f6992-a762-474f-a879-acfb6f106bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad4fcb-bf9b-4b48-bc94-9f8d58c24970",
   "metadata": {},
   "source": [
    "미리 학습된 모델의 체크포인트를 세팅한다. 여기서 사용할 모델은 한국어와 영어에 미리 학습된 [KE-T5](https://github.com/AIRC-KETI/ke-t5)모델을 사용한다. T5모델은 트랜스포머의 인코더, 디코더 구조를 모두 사용하는 모델로 번역기를 만들 때 사용할 수 있는 모델이다. 아래처럼 모델 체크 포인트와 T5 모델에 입력될 최대 토큰 길이를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a354a6f-8561-4b4b-82a5-37e23684de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"KETI-AIR/ke-t5-base\"\n",
    "max_token_length = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e219e4e-e336-4d5f-ab51-cbe84c824937",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "먼저 모델 체크 포인트를 사용하여 KE-T5 모델이 학습할때 함께 사용한 토크나이저를 불러온다. 허깅페이스 트랜스포머스 라이브러리를 사용할 때 가장 핵심이 되며 익숙해지기 쉽지 않은 부분이 이 토크나이저라고 개인적으로 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0995a847-c994-40cd-9842-14124cbc91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0cc164-b77e-4c69-86ee-504f04462b49",
   "metadata": {},
   "source": [
    "토크나이저를 로딩할때 `sentencepiece`가 없다고 에러가 나면 아래 명령으로 토크나이저가 사용하는 라이브러리를 설치하고 다시 로딩한다.\n",
    "\n",
    "```\n",
    "!pip install sentencepiece\n",
    "```\n",
    "\n",
    "\n",
    "토크나이저를 불러왔으니 현재 사용하는 데이터셋에서 샘플을 가져와 토크나이징해보는 것이 좋을 것이다. 학습 세트에서 10번 샘플을 가지고 실험해보자. 먼저 10번 샘플을 뿌려보고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c2c8534-348e-4d94-9f0c-e252a52e666e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Any academic achievement requires constant repetition.',\n",
       " '어떤 학문이든지 일정의 성취를 이루기 위해서는 끊임없는 반복이 필요하다.')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][10]['en'], dataset['train'][10]['ko']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4e727-e02e-407b-97ef-6f09ae9798b1",
   "metadata": {},
   "source": [
    "토크나이저에 각 문장을 입력하고 토큰화된 상태로 돌려 받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ec77c5c-001e-46c5-b9e5-74a243a6b676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [13941, 10114, 25542, 9361, 20526, 742, 32268, 12520, 3, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sample_en = tokenizer(dataset['train'][10]['en'], \n",
    "                                max_length=max_token_length, \n",
    "                                padding=True, truncation=True)\n",
    "tokenized_sample_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "686978da-d8bc-427c-9ae7-2d41a940a7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [404, 12663, 15, 10775, 2334, 6, 15757, 21, 29819, 1736, 26778, 4342, 15, 1701, 3, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sample_ko = tokenizer(dataset['train'][10]['ko'], \n",
    "                                max_length=max_token_length, \n",
    "                                padding=True, truncation=True)\n",
    "tokenized_sample_ko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c77bca-c4ea-486a-aaba-4bc7a18b1264",
   "metadata": {},
   "source": [
    "문장에 토큰으로 쪼개지고 각 토큰이 숫자로 변환된 것을 볼 수 있다. 이렇게 숫자화된 토큰을 `input_ids`로 반환하고 추가로 트랜스포머 인코더, 디코더에 쓰일 패딩 마스크도 함께 `attention_mask`로 돌려준다. 마스크가 모두 1인 이유는 샘플이 하나밖에 없어서 이다. 샘플 몇개를 더 실험해보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8232db64-a06f-478f-8452-02c790bc85ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[388, 6809, 2952, 17, 8, 32204, 43, 8023, 6687, 28, 9495, 91, 3, 1], [4014, 322, 3170, 147, 67, 23274, 3, 1, 0, 0, 0, 0, 0, 0], [11783, 4412, 96, 6556, 709, 1632, 3, 1, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(dataset['train'][:3]['en'], \n",
    "          max_length=max_token_length, \n",
    "          padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaccc9d-b892-4a5e-82bf-32b28426a685",
   "metadata": {},
   "source": [
    "미니배치에 있는 샘플의 최대길이메 맞춰서 패딩되는 모습을 확인할 수 있다. 실제로 어떻게 토큰화 되었는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6808b411-05b9-45d1-bccf-bb2ca78d345e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ids</th>\n",
       "      <td>13941</td>\n",
       "      <td>10114</td>\n",
       "      <td>25542</td>\n",
       "      <td>9361</td>\n",
       "      <td>20526</td>\n",
       "      <td>742</td>\n",
       "      <td>32268</td>\n",
       "      <td>12520</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Any</td>\n",
       "      <td>▁academic</td>\n",
       "      <td>▁achievement</td>\n",
       "      <td>▁requires</td>\n",
       "      <td>▁constant</td>\n",
       "      <td>▁re</td>\n",
       "      <td>pet</td>\n",
       "      <td>ition</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1             2          3          4    5      6  \\\n",
       "ids     13941      10114         25542       9361      20526  742  32268   \n",
       "tokens   ▁Any  ▁academic  ▁achievement  ▁requires  ▁constant  ▁re    pet   \n",
       "\n",
       "            7  8     9  \n",
       "ids     12520  3     1  \n",
       "tokens  ition  .  </s>  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        tokenized_sample_en['input_ids'],\n",
    "        tokenizer.convert_ids_to_tokens(tokenized_sample_en['input_ids'])\n",
    "    ], index=('ids', 'tokens')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "693b6a83-1db1-4463-9b90-a0f2053080d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ids</th>\n",
       "      <td>404</td>\n",
       "      <td>12663</td>\n",
       "      <td>15</td>\n",
       "      <td>10775</td>\n",
       "      <td>2334</td>\n",
       "      <td>6</td>\n",
       "      <td>15757</td>\n",
       "      <td>21</td>\n",
       "      <td>29819</td>\n",
       "      <td>1736</td>\n",
       "      <td>26778</td>\n",
       "      <td>4342</td>\n",
       "      <td>15</td>\n",
       "      <td>1701</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁어떤</td>\n",
       "      <td>▁학문</td>\n",
       "      <td>이</td>\n",
       "      <td>든지</td>\n",
       "      <td>▁일정</td>\n",
       "      <td>의</td>\n",
       "      <td>▁성취</td>\n",
       "      <td>를</td>\n",
       "      <td>▁이루기</td>\n",
       "      <td>▁위해서는</td>\n",
       "      <td>▁끊임없는</td>\n",
       "      <td>▁반복</td>\n",
       "      <td>이</td>\n",
       "      <td>▁필요하다</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1   2      3     4  5      6   7      8      9      10    11  \\\n",
       "ids     404  12663  15  10775  2334  6  15757  21  29819   1736  26778  4342   \n",
       "tokens  ▁어떤    ▁학문   이     든지   ▁일정  의    ▁성취   를   ▁이루기  ▁위해서는  ▁끊임없는   ▁반복   \n",
       "\n",
       "        12     13 14    15  \n",
       "ids     15   1701  3     1  \n",
       "tokens   이  ▁필요하다  .  </s>  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        tokenized_sample_ko['input_ids'],\n",
    "        tokenizer.convert_ids_to_tokens(tokenized_sample_ko['input_ids'])\n",
    "    ], index=('ids', 'tokens')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2e2ff-83bb-4bb6-9a44-2759bd4a487d",
   "metadata": {},
   "source": [
    "KE-T5를 학습할때 학습된 규칙대로 토큰화가 진행된다. 영어에서 `repetition`은 `re`, `pet`, `ition`으로 쪼개진 것을 볼 수 있고, 한국어에서 `성취를`은 `성취`, `를`로 쪼개지고 `학문이든지`는 `학문`, `이`, `든지`로 쪼개진것을 볼 수 있다. 토큰 앞에 _표시는 이 토큰 앞에는 공백이 있어야 한다는 의미다. 그리고 마지막에 엔드 토큰인 `</s>`가 항상 붙게 되는 것도 확인할 수 있다.\n",
    "\n",
    "이제 앞서 tsv파일로 부터 로딩한 `dataset`내의 문장을 모두 토크나이저를 사용해서 숫자로 바꾸는 작업을 해야 한다. 즉 문자로된 문장을 숫자로 바꿔 특성화 해야 한다. `dataset.map()`함수에 각 샘플을 토큰화 하는 함수를 만들어 전달하면 `map()`이 모든 샘플에 대해 전달받은 함수를 적용하게 되는데 함수는 이렇게 작성하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbe9dd2f-ac05-42f0-b9ec-71589bc3d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples):\n",
    "    ###########################################################################\n",
    "    # with 쓰는 옛날 방식\n",
    "    # input_encodings = tokenizer(examples['en'], \n",
    "    #                             max_length=max_token_length, truncation=True)\n",
    "    \n",
    "    # Setup the tokenizer for targets\n",
    "    # with tokenizer.as_target_tokenizer():\n",
    "    # target_encodings = tokenizer(text_target=examples['ko'], \n",
    "    #                             max_length=max_token_length, truncation=True)\n",
    "    #\n",
    "    #\n",
    "    # return {\n",
    "    #     \"input_ids\": input_encodings[\"input_ids\"],\n",
    "    #     \"attention_mask\": input_encodings[\"attention_mask\"],\n",
    "    #     \"labels\": target_encodings[\"input_ids\"]\n",
    "    # }\n",
    "    \n",
    "    # 그런데 이렇게 하면 인풋하고 한번에 처리 가능함.\n",
    "    model_inputs = tokenizer(examples['en'],\n",
    "                             text_target=examples['ko'], \n",
    "                             max_length=max_token_length, truncation=True)\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e84c49-8e0b-46d7-aada-bc84afc0e5cc",
   "metadata": {},
   "source": [
    "`convert_examples_to_features()`가 하고 싶은 일은 `dataset`에 있는 \"어떤 학문이든지 일정의 성취를 이루기 위해서는 끊임없는 반복이 필요하다.\"라는 샘플 문장을 `[404,12663,15,10775,2334,6,15757,21,29819,1736,26778,4342,15,1701,3,1]`라는 정수로 바꾸는 것이다. `convert_examples_to_features()`가 `dataset`에 적용될 때 넘겨 받는 `examples`는 다음과 같이 넘어 온다.\n",
    "\n",
    "```python\n",
    "examples= {'en':['sent1', 'sent2', ... , 'sent1000'], # 이건 문장 1000개짜리 리스트\n",
    "           'ko':['sent1', 'sent2', ... , 'sent1000']}\n",
    "```\n",
    "\n",
    "기본으로 미니 배치 사이즈는 1000으로 세팅되어 있다.(함수 기본인자는 [여기](https://huggingface.co/docs/datasets/v2.9.0/en/package_reference/main_classes#datasets.Dataset.map)서 확인 가능) \n",
    "\n",
    "미니 배치로 넘어온 문장 샘플을 영어 문장과 한국어 문장을 각각 인풋과 타겟으로 토큰화하고 이로 부터 `input_ids`, `attention_mask`, `labels`로 묶어 리턴하는 방식이 예전에 쓰던 방식으로 함수 위쪽에 주석처리 되어 있다. 타겟 문장을 토큰화 할 때 타겟에서 필요로 하는 특수 토큰을 추가하는 경우 이를 처리하기위해 타겟 토큰 토큰화 때는 `with tokenizer.as_target_tokenizer():`라는 컨텍스트 매니저를 사용했는데 최근 업데이트에서는 그냥 `tokenizer`에 `text_target`인자에 타겟 문장을 넣어서 한번에 다 처리할 수 있다. 이렇게 `model_inputs`을 반환하면 `dataset`에 있던 각 레코드 마다 `en`, `ko` 특성에 추가로 `input_ids`, `attention_mask`, `labels` 특성이 더 추가 되게 된다. 사실 `en`, `ko` 특성은 더이상 필요없기 때문에 `convert_examples_to_features()`를 적요할 때 없애라는 인자를 세팅한다. 바로 `dataset`에 함수를 적용해보자.\n",
    "\n",
    "그냥 해도되나 좀 더 빠르게 하기 위해 `num_proc` 인자에 스레드 개수를 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c91dd404-676b-4898-ac3d-9f3a418b3d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CPU = multiprocessing.cpu_count() // 2\n",
    "NUM_CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f02eb4-abf5-42e9-8fa7-77c49bb0d49f",
   "metadata": {},
   "source": [
    "그리고 `remove_columns` 인자에 기존 특성 이름인 `en`, `ko`를 전달해서 기존 특성은 제거하게 한다. 이 특성이 있으면 이후 콜레이터가 샘플들을 미니 배치로 묶을 때 패딩처리를 못하게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "561ed9cd-9d74-495e-8102-f71c41bd9946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb93cea73c254058827f9367b4e4a302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9901bae6fa824a28b3e3b287bd935739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da36d179315242129454d5effe646f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30bdd66d3ac4a06aca8ad3a8da933f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3f4d07c23c40f498bda1a917c20f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa8b1f812044fccb93023960131ad01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce98dbbe826a466db2e06bcfd63f23dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a094352a83143a9bb55cbb12cd85dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e053275b3774bffb52d96d20ee73ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94231d222ef94d549d7431c877c72dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8faba0376048a98d75e66470397737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe53971dd53462b8d2625da0e59a9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff3db25c111442183b3799b094e3ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee4fad1c7524b9c828d0ac84413dc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4088a36f5864970a41cb4fb5d4d380e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a17d741979c4fd4a2517b8cf815abca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0c430e936e42ee9ab25454dc3fe756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acb4a9b04484fd187f831395a19b581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276517f032f34c72808e3d8aac74febe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782b1b3e160f415d8b6cd2e7e362f71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ae5cb685ac468b882a30bf14e5a369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7ecd50da364136b979965d1b1c7298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a448ba99f3a4cdeb6da460d30c06e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9652709d3f4afab2922f396b37eab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed3eb7a74db4867b04a9d9c0a255b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d3d9c5c6c7438d89c7c20de84f5906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fdd304ea65426da21efec48cb1d9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0698c067bd4d19b49106b85544655a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddc0b2bd8f34fe288ecb32e90766c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2270778600e7454db71083f11b567e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(convert_examples_to_features, \n",
    "                                 batched=True, \n",
    "                                 # 이걸 쓰지 않으면 원 데이터 'en', 'ko'가 남아서\n",
    "                                 # 아래서 콜레이터가 패딩을 못해서 에러남\n",
    "                                 remove_columns=dataset[\"train\"].column_names,\n",
    "                                 num_proc=NUM_CPU) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ec637-0066-4b64-9c11-874c3cdfcacf",
   "metadata": {},
   "source": [
    "`convert_examples_to_features()`이 `dataset`의 모든 샘플에 다 적용되고 나면 `tokenized_datasets`는 다음처럼 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "357697dd-10fe-4319-9065-695ffaf365fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1200000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 90000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05054ee-57ad-4a0d-96d5-90555e34e342",
   "metadata": {},
   "source": [
    "기존에 있던 특성 `en`, `ko`는 사라졌고 `en`은 `input_ids`와 `attention_mask`로 `ko`는 `labels`로 바뀐것을 확인할 수 있다. 예를 들어 학습 세트에 10번 데이터를 보면 다음처럼 다 숫자라 바뀌게 된것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "761f5fa1-8cc8-4f5d-b730-8d34f60b9ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [13941, 10114, 25542, 9361, 20526, 742, 32268, 12520, 3, 1],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [404,\n",
       "  12663,\n",
       "  15,\n",
       "  10775,\n",
       "  2334,\n",
       "  6,\n",
       "  15757,\n",
       "  21,\n",
       "  29819,\n",
       "  1736,\n",
       "  26778,\n",
       "  4342,\n",
       "  15,\n",
       "  1701,\n",
       "  3,\n",
       "  1]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca3d7c-a8de-458b-8596-d3213f54713a",
   "metadata": {},
   "source": [
    "토크나이저를 써서 숫자로 부터 토큰화 해보면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "262eafbc-6499-4862-aaaf-b539d22df130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원 데이터    : Any academic achievement requires constant repetition.\n",
      "처리 후 데이터: [13941, 10114, 25542, 9361, 20526, 742, 32268, 12520, 3, 1]\n",
      "토큰화       : ['▁Any', '▁academic', '▁achievement', '▁requires', '▁constant', '▁re', 'pet', 'ition', '.', '</s>']\n",
      "\n",
      "\n",
      "원 데이터    : 어떤 학문이든지 일정의 성취를 이루기 위해서는 끊임없는 반복이 필요하다.\n",
      "처리 후 데이터: ['▁어떤', '▁학문', '이', '든지', '▁일정', '의', '▁성취', '를', '▁이루기', '▁위해서는', '▁끊임없는', '▁반복', '이', '▁필요하다', '.', '</s>']\n",
      "토큰화       : [404, 12663, 15, 10775, 2334, 6, 15757, 21, 29819, 1736, 26778, 4342, 15, 1701, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "print( '원 데이터    :', dataset['train'][10]['en'] )\n",
    "print( '처리 후 데이터:', tokenized_datasets['train'][10]['input_ids'] )\n",
    "print( '토큰화       :', tokenizer.convert_ids_to_tokens(tokenized_datasets['train'][10]['input_ids']) )\n",
    "\n",
    "print('\\n')\n",
    "print( '원 데이터    :', dataset['train'][10]['ko'] )\n",
    "print( '처리 후 데이터:', tokenizer.convert_ids_to_tokens(tokenized_datasets['train'][10]['labels']) )\n",
    "print( '토큰화       :', tokenized_datasets['train'][10]['labels'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb05947-a1b0-498f-9ae2-35a11c47e723",
   "metadata": {},
   "source": [
    "데이터 특성화를 모두 마쳤으므로 이제 모델을 로딩하자. `AutoModelForSeq2SeqLM`를 사용해서 선학습 모델을 불러오면 선학습된 T5모델 마지막에 파인튜닝할 수 있는 분류 헤드를 붙인 모델을 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba2636-1b8c-415c-9a19-b2ffeed589c4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82e7ec24-49ea-457a-bfcb-73fed79a9766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488ebba-aa28-4c85-8ad7-ad0d9c5cd756",
   "metadata": {},
   "source": [
    "위처럼 모델을 로딩하고 모델 출력 시켜보면 T5 모델 레이어가 매우 길게 출력되는데 제일 마지막 부분에 다음과 같이 분류 헤드가 붙어 있는 것을 확인할 수 있다. 헤드를 보면 모델에서 출력하는 벡터는 768차원이고 이를 단어장 사이즈인 64128로 변환시키고 있는 것을 알 수 있다.\n",
    "\n",
    "```\n",
    "(lm_head): Linear(in_features=768, out_features=64128, bias=False)\n",
    "```\n",
    "\n",
    "이렇게 생성된 `model`은 인코더-디코더 구조를 가지는 트랜스포머이므로 이 모델을 포워딩 하려면 인코더 인풋과 디코더 인풋을 넣어줘야 한다. 모델을 만들고 가장 먼저해야되는 작업은 포워딩 테스트라고 개인적으로 생각한다. 임의의 입력을 넣고 출력이 의도대로 나오는지 확인하는 것이다. 이런 작업은 직접 만든 모델이 아닐 수록 중요한데 이렇게 해야지 모델이 제대로 작동하는지 또 어떤 구조로 되어 있는지 쉽게 이해할 수 있기 때문이다. 포워드 테스트를 하기위해 간단한 영어문장으로 예제를 준비한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c84561f1-678d-4ae4-ab36-91ca3766eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tokenizer(\n",
    "    [\"Studies have been shown that owning a dog is good for you\"], \n",
    "    return_tensors=\"pt\"\n",
    ")['input_ids'].to(device)\n",
    "\n",
    "decoder_targets = tokenizer(\n",
    "    [\"개를 키우는 것이 건강에 좋다는 연구 결과가 있습니다.\"], \n",
    "    return_tensors=\"pt\"\n",
    ")['input_ids'].to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003763c-759a-4dd0-8c67-96d46d2c49be",
   "metadata": {},
   "source": [
    "영어 문장은 인코더의 입력이 되고 한국어 문장은 디코더의 타겟이 된다. 아래처럼 모두 숫자로 변환되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7d0898a-451f-4a73-97d6-0fa51699df3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24611,    84,   166,  8135,    38,   847,    91,    16,  8146,    43,\n",
      "           667,    40,   106,     1]], device='cuda:0')\n",
      "tensor([[15833, 12236,   179, 16120, 28117,  1007,  3883,   327,     3,     1]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print( encoder_inputs )\n",
    "print( decoder_targets )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb132c9-959a-40ab-9795-84001af7ff6c",
   "metadata": {},
   "source": [
    "이제 디코더 입력을 만들기위해 `model._shift_right`를 사용해 디코더 출력을 오른쪽으로 쉬프트 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19c4ea3a-d846-4666-97ad-68f36cddf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = model._shift_right(decoder_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba7551-19a7-43db-85d0-d79c61a48399",
   "metadata": {},
   "source": [
    "`shifted`와 `decoder_inputs`이 어떻게 다른지 비교해보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "916784d6-724e-46a1-96d5-b2bc72c90c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decoder target</th>\n",
       "      <td>▁개를</td>\n",
       "      <td>▁키우는</td>\n",
       "      <td>▁것이</td>\n",
       "      <td>▁건강에</td>\n",
       "      <td>▁좋다는</td>\n",
       "      <td>▁연구</td>\n",
       "      <td>▁결과가</td>\n",
       "      <td>▁있습니다</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder input</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>▁개를</td>\n",
       "      <td>▁키우는</td>\n",
       "      <td>▁것이</td>\n",
       "      <td>▁건강에</td>\n",
       "      <td>▁좋다는</td>\n",
       "      <td>▁연구</td>\n",
       "      <td>▁결과가</td>\n",
       "      <td>▁있습니다</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0     1     2     3     4     5     6      7      8     9\n",
       "decoder target    ▁개를  ▁키우는   ▁것이  ▁건강에  ▁좋다는   ▁연구  ▁결과가  ▁있습니다      .  </s>\n",
       "decoder input   <pad>   ▁개를  ▁키우는   ▁것이  ▁건강에  ▁좋다는   ▁연구   ▁결과가  ▁있습니다     ."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        tokenizer.convert_ids_to_tokens(decoder_targets[0]),\n",
    "        tokenizer.convert_ids_to_tokens(decoder_inputs[0])\n",
    "    ],\n",
    "    index=('decoder target', 'decoder input')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c83b08-077a-43bb-975c-f2df51071675",
   "metadata": {},
   "source": [
    "위처럼 오른쪽으로 쉬프트된 디코더 입력은 `<pad>` 토큰이 추가되었다. 이렇게 출력으로 쓰이는 문장을 오른쪽으로 쉬프트시켜 티처포싱Teacher forcing을 진행하게 된다. 다음처럼 `model`에 인코더 입력, 디코더 입력, 디코더 타겟을 입력하고 포워드 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f47e2f4b-3f1a-47da-8b81-6b90e992aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "outputs = model(input_ids=encoder_inputs, \n",
    "                decoder_input_ids=decoder_inputs, \n",
    "                labels=decoder_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8b6f9-80b0-4d07-9b3a-ef197883b986",
   "metadata": {},
   "source": [
    "`model`의 `outputs`에는 다음과 같은 키가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5084b428-d776-47fa-9c9c-f76bf3c99243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d660b-50eb-4f64-94cb-eda51f33c63f",
   "metadata": {},
   "source": [
    "손실함수 값을 다음처럼 확인할 수 있고 `grad_fn`이 있기 때문에 `output.loss`를 백워드 시킬 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d830740-8fda-47bc-858c-290ca1681f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(87.8185, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2227e-68eb-4a63-97e5-f034afbe536e",
   "metadata": {},
   "source": [
    "인코더의 마지막 상태는 (1, 14, 768)이다. 각 숫자는 순서대로 샘플 수, 스탭 수, 모델 사이즈를 나타낸다. 즉 인코더로 들어가는 14개 토큰이 각각 768차원 벡터로 인코딩되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d99482a-78c2-40f5-a563-2e8312d377b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 768])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['encoder_last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e681f2-851e-4ec4-aee6-223bed51dc26",
   "metadata": {},
   "source": [
    "`logit`은 디코더 입력 토큰 10개에 대한 그 다음 토큰 예측 10개를 담고있다. 샘플 한개에 대해서 10개 토큰에 대해서 64128개 단어에 대한 확률값이 들어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24ad8e3c-2910-4e04-bff5-693393ddb7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 64128])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['logits'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefa5f3-654f-40c4-81cb-3e0b9145c64a",
   "metadata": {},
   "source": [
    "`logit`에 `argmax`를 씌워서 토큰화시켜보면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "517afe80-a33c-4938-a07b-9c7e3024bf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['큐브', '큐브', '▁비일비재', '▁비일비재', '▁베네', '▁비일비재', '▁베네', '▁베네', '큐브', '큐브']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens( torch.argmax(outputs['logits'][0], axis=1).cpu().numpy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1376410-1816-46a5-88be-4b09d009134d",
   "metadata": {},
   "source": [
    "마지막 헤더가 학습이 되지 않았기 때문에 적절한 아웃풋이 나오지 않지만 입력과 출력의 텐서 모양을 보면 포워드 패스가 제대로 작동한다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b7769-2eb5-4acd-987e-6563a499daa1",
   "metadata": {},
   "source": [
    "## Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617fd4e-83d7-4b96-aee6-dd3a75c5fccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4095b10-346f-4c94-be51-8738d47ed1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba462e4-07bb-4de7-a049-951b599ac4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a57609-8fa4-4ec8-9949-b27f76e372e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f40676c-1393-423e-ad87-0c015f603bcb",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb743a-6e20-490c-8fa7-392c3a24e234",
   "metadata": {},
   "source": [
    "BLEU 점수는 번역기가 생성한 문장이 레퍼런스(정답이라는 표현을 사용하지 않는 이유는 제대로 된 번역 문장이 오직 하나가 아니기 때문)문장과 얼마나 비슷한지 측정하는 점수라고 생각하면 된다. 단 같은 단어가 반복된다든지 레퍼런스 문장보다 너무 짧은 문장을 생성한다든지 하면 패널티를 부여 한다. 그렇기 때문에 길이가 최대한 비슷하고 다양한 단어를 사용하면서 생성된 문장의 단어가 레퍼런스 단어에 많이 보여야 높은 점수를 얻게 된다.\n",
    "\n",
    "\n",
    "BLEU를 계산하기 위해 다음 명령어로 허깅페이스 [evaluate](https://huggingface.co/docs/evaluate/index) 라이브러리를 설치하고 [sacrebleu](https://huggingface.co/spaces/evaluate-metric/sacrebleu)라이브러리도 함께 설치하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69824ea-1347-4321-9173-7784e833a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b5431-decf-4bb0-bc7b-7b3c9a3edd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00382b4a-a0b2-4ee8-8a18-9fda35053bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f392bab4-36af-4d6f-909e-bffcf62f7d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 11.532935342795522,\n",
       " 'counts': [12, 3, 1, 0],\n",
       " 'totals': [21, 19, 17, 15],\n",
       " 'precisions': [57.142857142857146,\n",
       "  15.789473684210526,\n",
       "  5.882352941176471,\n",
       "  3.3333333333333335],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 21,\n",
       " 'ref_len': 21}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    \"저는 깊이 있는 학습을 좋아해요.\",\n",
    "    \"딥러닝 틀이 잘 개발되기 때문에 요즘은 누군가의 도움 없이 기계번역 시스템을 구축할 수 있다.\"\n",
    "]\n",
    "\n",
    "references = [\n",
    "    [\"저는 딥러닝을 좋아해요.\", \"나는 딥러닝을 사랑해요.\"],\n",
    "    [\"요즘은 딥러닝 프레임워크가 잘 발달되어 있기 때문에 누구의 도움 없이도 기계 번역 시스템을 구축할 수 있습니다.\",\n",
    "     \"최근에는 딥러닝 프레임워크가 잘 개발되어 있기 때문에 다른 사람의 도움 없이도 기계 번역 시스템을 개발할 수 있습니다.\"]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683a8f57-668e-4f37-99dd-78a2ed390e5b",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4813d2f-3a73-4a5b-a9e6-3175ce16400b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
